# Memory Optimization Guide

**Status**: âœ… COMPLETE (Phases 1-3)  
**Last Updated**: February 20, 2026  
**Production Ready**: Yes

> **ðŸ“‹ See [MEMORY_OPTIMIZATION_COMPLETE.md](../../MEMORY_OPTIMIZATION_COMPLETE.md) for full implementation summary**

## Quick Links

- **Implementation Summary**: [MEMORY_OPTIMIZATION_COMPLETE.md](../../MEMORY_OPTIMIZATION_COMPLETE.md)
- **Phase 1 Details**: [MEMORY_OPTIMIZATION_PHASE_1_COMPLETE.md](../../MEMORY_OPTIMIZATION_PHASE_1_COMPLETE.md)
- **Phase 2 Details**: [MEMORY_OPTIMIZATION_PHASE_2_FINAL.md](../../MEMORY_OPTIMIZATION_PHASE_2_FINAL.md)
- **Phase 3 Details**: [MEMORY_OPTIMIZATION_PHASE_3_COMPLETE.md](../../MEMORY_OPTIMIZATION_PHASE_3_COMPLETE.md)
- **Spec Tasks**: [.kiro/specs/memory-optimization/tasks.md](../../.kiro/specs/memory-optimization/tasks.md)

---

## Quick Reference

This guide provides practical information for developers working with CatchUp's memory optimization features.

## Overview

CatchUp implements a comprehensive memory optimization strategy to prevent heap exhaustion crashes and support large datasets (100,000+ contacts per user). The system uses:

1. **Memory Circuit Breaker**: Prevents operations when heap > 80%
2. **Memory Monitor**: Tracks usage and detects leaks
3. **Streaming Repository**: Processes contacts without loading all into memory
4. **LRU Caches**: Bounds cache memory to 185MB max
5. **Optimized Queries**: 90% reduction in query memory usage
6. **Batch Limits**: Max 50 suggestions per user
7. **Forced GC**: Releases memory between batches
8. **Memory Logging**: Detailed tracking for debugging

**Performance**: 75-80% memory reduction, supports 100,000+ contacts per user

## Using Memory Circuit Breaker

### Basic Usage

```typescript
import { MemoryCircuitBreaker } from '../utils/memory-circuit-breaker';

const breaker = new MemoryCircuitBreaker({ maxHeapPercent: 80 });

// Check memory before expensive operation
await breaker.checkMemory();

// Or wrap operation with automatic checks
const result = await breaker.execute(async () => {
  // Your expensive operation here
  return processLargeDataset();
});
```

### Configuration Options

```typescript
interface MemoryCircuitBreakerOptions {
  maxHeapPercent: number;    // Default: 80 (threshold %)
  checkIntervalMs: number;   // Default: 1000 (not used currently)
  enableLogging: boolean;    // Default: true
}
```

### Error Handling

```typescript
import { MemoryCircuitBreakerError } from '../utils/memory-circuit-breaker';

try {
  await breaker.execute(async () => {
    return processData();
  });
} catch (error) {
  if (error instanceof MemoryCircuitBreakerError) {
    console.error('Memory threshold exceeded:', error.memoryUsage);
    // Return partial results or retry with smaller batch
    return handleMemoryPressure();
  }
  throw error;
}
```

## Using Memory Monitor

### Basic Usage

```typescript
import { MemoryMonitor } from '../utils/memory-monitor';

const monitor = new MemoryMonitor();

// Log memory for an operation
const before = process.memoryUsage();
const result = await processData();
const after = process.memoryUsage();
monitor.logMemoryUsage('process-data', before, after);

// Or wrap operation for automatic tracking
const result = await monitor.wrapOperation('process-data', async () => {
  return processData();
});
```

### Configuration Options

```typescript
interface MemoryMonitorOptions {
  sampleIntervalMs: number;   // Default: 60000 (1 minute)
  maxSamples: number;         // Default: 60 (1 hour of data)
  growthThreshold: number;    // Default: 1.5 (50% growth)
  enableAlerts: boolean;      // Default: true
}
```

### Continuous Monitoring

```typescript
const monitor = new MemoryMonitor({
  sampleIntervalMs: 60000,  // Sample every minute
  maxSamples: 60,           // Keep 1 hour of data
  growthThreshold: 1.5,     // Alert on 50% growth
});

// Start monitoring
monitor.start();

// Your application runs...

// Stop monitoring
monitor.stop();

// Check for leaks
const leakResult = monitor.detectLeak();
if (leakResult?.detected) {
  console.warn('Memory leak detected:', leakResult);
}
```

## Best Practices

### 1. Always Check Memory Before Expensive Operations

```typescript
// âœ… Good
const breaker = new MemoryCircuitBreaker();
await breaker.checkMemory();
const result = await processLargeDataset();

// âŒ Bad
const result = await processLargeDataset(); // No memory check
```

### 2. Use Memory Monitoring for Long-Running Operations

```typescript
// âœ… Good
const monitor = new MemoryMonitor();
const result = await monitor.wrapOperation('long-operation', async () => {
  return processData();
});

// âŒ Bad
const result = await processData(); // No tracking
```

### 3. Force GC After Batch Processing

```typescript
// âœ… Good
for (const batch of batches) {
  await processBatch(batch);
  
  // Force GC if available
  if (global.gc) {
    global.gc();
  }
  
  // Yield to event loop
  await new Promise(resolve => setImmediate(resolve));
}

// âŒ Bad
for (const batch of batches) {
  await processBatch(batch); // No GC, no yielding
}
```

### 4. Limit Result Set Sizes

```typescript
// âœ… Good
const MAX_RESULTS = 50;
const results = await fetchData();
return results.slice(0, MAX_RESULTS);

// âŒ Bad
const results = await fetchData();
return results; // Unbounded
```

### 5. Handle Memory Errors Gracefully

```typescript
// âœ… Good
try {
  return await processAllData();
} catch (error) {
  if (error instanceof MemoryCircuitBreakerError) {
    // Return partial results
    return await processPartialData();
  }
  throw error;
}

// âŒ Bad
return await processAllData(); // No error handling
```

## Memory Logging

### Log Format

```typescript
[Memory] operation-name: {
  heapUsed: "1234.56 MB",
  heapTotal: "2048.00 MB",
  heapPercent: "60.3%",
  heapDiff: "+123.45 MB",
  rss: "1500.00 MB"
}
```

### Interpreting Logs

- **heapUsed**: Current heap memory in use
- **heapTotal**: Total heap size allocated
- **heapPercent**: Percentage of heap used (alert if > 70%)
- **heapDiff**: Change in heap usage (+ increase, - decrease)
- **rss**: Resident Set Size (total memory including heap, stack, code)

### Warning Thresholds

- **70%**: Warning logged
- **80%**: Circuit breaker triggers
- **90%**: Critical, immediate action needed

## Configuration

### Environment Variables

```bash
# Memory configuration (optional, uses defaults if not set)
MAX_HEAP_PERCENT=80
SUGGESTION_BATCH_SIZE=100
MAX_SUGGESTIONS_PER_GENERATION=50
ENABLE_MEMORY_MONITORING=true
ENABLE_FORCED_GC=true
```

### Node.js Flags

```bash
# Required for forced GC
node --expose-gc index.js

# Increase heap size if needed (default: 2GB)
node --max-old-space-size=4096 index.js

# Combined
node --expose-gc --max-old-space-size=4096 index.js
```

## Troubleshooting

### High Memory Usage

**Symptoms**: Heap usage consistently > 70%

**Solutions**:
1. Check for memory leaks using `MemoryMonitor.detectLeak()`
2. Reduce batch sizes
3. Increase forced GC frequency
4. Profile with heap snapshots

### Memory Circuit Breaker Triggering

**Symptoms**: `MemoryCircuitBreakerError` thrown frequently

**Solutions**:
1. Reduce batch sizes
2. Limit result set sizes
3. Increase heap size temporarily
4. Investigate memory leaks

### Memory Leaks Detected

**Symptoms**: `[Memory] Potential leak detected` warnings

**Solutions**:
1. Take heap snapshot: `node --expose-gc --heap-prof index.js`
2. Analyze with Chrome DevTools
3. Look for:
   - Retained objects
   - Detached DOM nodes
   - Closure retentions
   - Unbounded arrays/maps

### Slow Performance

**Symptoms**: Operations taking longer than expected

**Solutions**:
1. Check if forced GC is too frequent
2. Reduce memory check frequency
3. Profile with `--prof` flag
4. Optimize hot paths

## Testing

### Unit Tests

```bash
# Test memory utilities
npm test src/utils/memory-circuit-breaker.test.ts
npm test src/utils/memory-monitor.test.ts
```

### Integration Tests

```bash
# Test with real data
npm run dev

# Monitor logs for memory tracking
# Look for [Memory] log entries
```

### Load Tests

```bash
# Test with large datasets (Phase 4)
npm run load-test:contacts -- --count=10000
npm run load-test:concurrent -- --users=10
```

## Monitoring in Production

### Key Metrics

- Heap usage percent
- Memory circuit breaker triggers
- Memory leak alerts
- Operation duration
- GC frequency

### Alerting

Set up alerts for:
- Heap usage > 90% for > 1 minute
- Memory circuit breaker triggered > 5 times/hour
- Memory leak detected
- Process crash with OOM error

### Dashboards

Monitor:
- Heap usage over time
- Memory per operation
- GC frequency and duration
- Circuit breaker state

## Related Documentation

- **Spec**: `.kiro/specs/memory-optimization/`
- **Phase 1 Summary**: `MEMORY_OPTIMIZATION_PHASE_1_COMPLETE.md`
- **Testing Guide**: `.kiro/steering/testing-guide.md`
- **Tech Standards**: `.kiro/steering/tech.md`

## Examples

### Example 1: Batch Processing with Memory Management

```typescript
import { MemoryCircuitBreaker } from '../utils/memory-circuit-breaker';
import { MemoryMonitor } from '../utils/memory-monitor';

async function processBatchJob(items: any[]) {
  const breaker = new MemoryCircuitBreaker({ maxHeapPercent: 80 });
  const monitor = new MemoryMonitor();
  
  const BATCH_SIZE = 100;
  const results = [];
  
  for (let i = 0; i < items.length; i += BATCH_SIZE) {
    // Check memory before batch
    await breaker.checkMemory();
    
    // Process batch with tracking
    const batch = items.slice(i, i + BATCH_SIZE);
    const batchResults = await monitor.wrapOperation(
      `process-batch-${i}`,
      async () => processBatch(batch)
    );
    
    results.push(...batchResults);
    
    // Force GC
    if (global.gc) {
      global.gc();
    }
    
    // Yield to event loop
    await new Promise(resolve => setImmediate(resolve));
  }
  
  return results;
}
```

### Example 2: Graceful Degradation

```typescript
import { MemoryCircuitBreaker, MemoryCircuitBreakerError } from '../utils/memory-circuit-breaker';

async function generateSuggestions(userId: string) {
  const breaker = new MemoryCircuitBreaker();
  const MAX_SUGGESTIONS = 50;
  
  try {
    // Try to generate full set
    await breaker.checkMemory();
    const suggestions = await generateAllSuggestions(userId);
    return suggestions.slice(0, MAX_SUGGESTIONS);
  } catch (error) {
    if (error instanceof MemoryCircuitBreakerError) {
      console.warn('Memory pressure detected, generating partial results');
      
      // Fall back to smaller batch
      const suggestions = await generatePartialSuggestions(userId, 25);
      return suggestions;
    }
    throw error;
  }
}
```

### Example 3: Continuous Monitoring

```typescript
import { MemoryMonitor } from '../utils/memory-monitor';

// Start monitoring on application startup
const monitor = new MemoryMonitor({
  sampleIntervalMs: 60000,  // 1 minute
  maxSamples: 60,           // 1 hour
  growthThreshold: 1.5,     // 50% growth
  enableAlerts: true,
});

monitor.start();

// Check for leaks periodically
setInterval(() => {
  const leakResult = monitor.detectLeak();
  if (leakResult?.detected) {
    console.error('Memory leak detected:', {
      growthPercent: leakResult.growthPercent,
      recommendation: leakResult.recommendation,
    });
    
    // Take action: alert, restart, etc.
  }
}, 5 * 60 * 1000); // Every 5 minutes

// Stop monitoring on shutdown
process.on('SIGTERM', () => {
  monitor.stop();
});
```

## FAQ

### Q: When should I use the memory circuit breaker?

A: Use it before any operation that processes large datasets or allocates significant memory (e.g., loading all contacts, generating suggestions, syncing data).

### Q: How often should I force GC?

A: After processing each batch of data. Don't force GC too frequently (< 1 second intervals) as it can hurt performance.

### Q: What's the difference between heap and RSS?

A: Heap is JavaScript object memory. RSS (Resident Set Size) is total memory including heap, stack, and code. Monitor heap for JavaScript memory issues.

### Q: Should I increase the heap size?

A: Only as a temporary measure. The goal is to optimize memory usage, not increase limits. Phase 2 (Streaming) will reduce memory needs by 60-80%.

### Q: How do I take a heap snapshot?

A: Run with `--heap-prof` flag or use Chrome DevTools. See [Node.js profiling guide](https://nodejs.org/en/docs/guides/simple-profiling/).

## Next Steps

- **Phase 2**: Implement streaming architecture for 60-80% memory reduction
- **Phase 3**: Add LRU caches and query optimization
- **Phase 4**: Load testing and performance benchmarking
